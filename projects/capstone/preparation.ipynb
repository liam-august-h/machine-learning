{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Mercari Price Suggestion Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import scipy as sp\n",
    "from scipy import stats, integrate\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def IQR(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    outlier_higher = q3 + 1.5 * iqr\n",
    "    outlier_lower = q1 - 1.5 * iqr\n",
    "    return outlier_lower, outlier_higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    \"train_id\" : np.int64,\n",
    "    \"name\" : np.str,\n",
    "    \"item_condition_id\" : np.uint8,\n",
    "    \"category_name\" : np.str,\n",
    "    \"brand_name\": np.str,\n",
    "    \"price\": np.float64,\n",
    "    \"shipping\": np.uint8,\n",
    "    \"item_description\": np.str\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orig_train_data = pd.read_csv(\"./data/train.tsv\", sep='\\t', dtype=dtypes)\n",
    "test_data = pd.read_csv(\"./data/test.tsv\", sep='\\t', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = orig_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1482535 rows in train_data and each row has 8 columns\n",
      "there are 693359 rows in test_data and each row has 7 columns\n",
      "train_data columns and their types: \n",
      "train_id               int64\n",
      "name                  object\n",
      "item_condition_id      uint8\n",
      "category_name         object\n",
      "brand_name            object\n",
      "price                float64\n",
      "shipping               uint8\n",
      "item_description      object\n",
      "dtype: object\n",
      "- test_data columns and their types: \n",
      "test_id               int64\n",
      "name                 object\n",
      "item_condition_id     uint8\n",
      "category_name        object\n",
      "brand_name           object\n",
      "shipping              uint8\n",
      "item_description     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"there are {} rows in train_data and each row has {} columns\".format(\n",
    "    train_data.shape[0], train_data.shape[1]))\n",
    "print(\"there are {} rows in test_data and each row has {} columns\".format(\n",
    "    test_data.shape[0], test_data.shape[1]))\n",
    "\n",
    "print(\"train_data columns and their types: \")\n",
    "print(train_data.dtypes)\n",
    "\n",
    "print(\"- test_data columns and their types: \")\n",
    "print(test_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297351</th>\n",
       "      <td>297351</td>\n",
       "      <td>Nike Lunarglide 7- size 6.5</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Nike</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pink grey and orange Nikes. Worn once but they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885669</th>\n",
       "      <td>885669</td>\n",
       "      <td>Elena locket with real Vervain</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Vampire Diaries Elena locket with real Vervain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195941</th>\n",
       "      <td>1195941</td>\n",
       "      <td>iPhone 6 iPhone 6s Case</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronics/Cell Phones &amp; Accessories/Cases, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>For iPhone 6 iPhone 6s Cute Baby Pacifier Milk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                            name  item_condition_id  \\\n",
       "297351     297351     Nike Lunarglide 7- size 6.5                  3   \n",
       "885669     885669  Elena locket with real Vervain                  1   \n",
       "1195941   1195941         iPhone 6 iPhone 6s Case                  1   \n",
       "\n",
       "                                             category_name brand_name  price  \\\n",
       "297351                                Women/Shoes/Athletic       Nike   36.0   \n",
       "885669                             Women/Jewelry/Necklaces        NaN   10.0   \n",
       "1195941  Electronics/Cell Phones & Accessories/Cases, C...        NaN   10.0   \n",
       "\n",
       "         shipping                                   item_description  \n",
       "297351          0  Pink grey and orange Nikes. Worn once but they...  \n",
       "885669          1  Vampire Diaries Elena locket with real Vervain...  \n",
       "1195941         1  For iPhone 6 iPhone 6s Cute Baby Pacifier Milk...  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426633</th>\n",
       "      <td>426633</td>\n",
       "      <td>UGG Boots</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>UGG Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>I am selling a NEW pair of UGG Boots.They are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545255</th>\n",
       "      <td>545255</td>\n",
       "      <td>Vera Bradley Large makeup bag</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Women's Handbags/Cosmetic Bags</td>\n",
       "      <td>Vera Bradley</td>\n",
       "      <td>1</td>\n",
       "      <td>Large bag double zipper Zipper pouch inside al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197893</th>\n",
       "      <td>197893</td>\n",
       "      <td>Women's Cardigan Sweater HOLD</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Sweaters/Cardigan</td>\n",
       "      <td>Mossimo</td>\n",
       "      <td>1</td>\n",
       "      <td>MOSSIMO •Women's XS cardigan sweater •Black •X...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        test_id                           name  item_condition_id  \\\n",
       "426633   426633                      UGG Boots                  1   \n",
       "545255   545255  Vera Bradley Large makeup bag                  3   \n",
       "197893   197893  Women's Cardigan Sweater HOLD                  2   \n",
       "\n",
       "                               category_name     brand_name  shipping  \\\n",
       "426633                     Women/Shoes/Boots  UGG Australia         0   \n",
       "545255  Women/Women's Handbags/Cosmetic Bags   Vera Bradley         1   \n",
       "197893               Women/Sweaters/Cardigan        Mossimo         1   \n",
       "\n",
       "                                         item_description  \n",
       "426633  I am selling a NEW pair of UGG Boots.They are ...  \n",
       "545255  Large bag double zipper Zipper pouch inside al...  \n",
       "197893  MOSSIMO •Women's XS cardigan sweater •Black •X...  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*test_id* and *train_id* could be ignored. *item_condition_id* and *shipping* are actually category data. *name*, *category_name*, *brand_name* and *item_description* are text data.\n",
    "Since *price* is the only continuous data and it is the output, seems there is no need to check distribution and normalize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create subsets of train_data and test_data to do trail exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data = train_data.sample(16384, random_state=37)\n",
    "sub_test_data = test_data.sample(16384, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id                  0\n",
       "name                      0\n",
       "item_condition_id         0\n",
       "category_name          6327\n",
       "brand_name           632682\n",
       "price                     0\n",
       "shipping                  0\n",
       "item_description          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isna(train_data).sum()\n",
    "#pd.isna(sub_train_data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop *Train_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_train_id(data):\n",
    "    return data.drop(columns=['train_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = drop_train_id(train_data)\n",
    "sub_train_data = drop_train_id(sub_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop NA item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_item_desc(data):\n",
    "    return data.drop(data[data['item_description'].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = drop_missing_item_desc(train_data)\n",
    "sub_train_data = drop_missing_item_desc(sub_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category *item_condition_id* and *shipping*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_fields(data):\n",
    "    data['item_condition_id'] = data['item_condition_id'].astype('category')\n",
    "    data['shipping'] = data['shipping'].astype('category')\n",
    "    print(data.item_condition_id.cat.categories)\n",
    "    print(data.shipping.cat.categories)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UInt64Index([1, 2, 3, 4, 5], dtype='uint64')\n",
      "UInt64Index([0, 1], dtype='uint64')\n",
      "UInt64Index([1, 2, 3, 4, 5], dtype='uint64')\n",
      "UInt64Index([0, 1], dtype='uint64')\n"
     ]
    }
   ],
   "source": [
    "sub_train_data = category_fields(sub_train_data)\n",
    "train_data = category_fields(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 items missing item_condition_id\n"
     ]
    }
   ],
   "source": [
    "print(\"there are \" + str(pd.isna(train_data['item_condition_id']).sum())\n",
    "      + \" items missing item_condition_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 items missing shipping\n"
     ]
    }
   ],
   "source": [
    "print(\"there are \" + str(pd.isna(train_data['shipping']).sum())\n",
    "      + \" items missing shipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *category_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normally, *category_name* is in a form like 'a/b/c', but some products *category_name* contain more than three '/' character. Like *Electronics/Computers & Tablets/iPad/Tablet/eB...*. There will be more than three segments if to split *category_name* with '/'. It's reasonable to keep first two first two segment and merge others. For example, *Electronics/Computers & Tablets/iPad/Tablet/eB...* is transfered to *Electronics*, *Computers & Tablets*, and *iPad/Tablet/eB...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_long_category(data):\n",
    "    long_category_product = data[data['category_name'].str.count('/') > 3]\n",
    "    return long_category_product['category_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electronics/Computers & Tablets/iPad/Tablet/eBook Readers'\n",
      " 'Electronics/Computers & Tablets/iPad/Tablet/eBook Access']\n"
     ]
    }
   ],
   "source": [
    "print(filter_long_category(sub_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_category(data):\n",
    "    splited = data['category_name'].str.split('/', expand=True)\n",
    "    splited[2] = np.where(splited[3].isnull(), \n",
    "                          splited[2], splited[2]+'/'+splited[3]+'/'+splited[4])\n",
    "    data['c1'], data['c2'], data['c3'] = splited[0], splited[1], splited[2]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data= split_category(sub_train_data)\n",
    "train_data = split_category(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_fields = ['name', 'category_name', 'brand_name', 'item_description',\n",
    "                   'c1', 'c2', 'c3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lowercase(data, fields=all_text_fields):\n",
    "    for field in fields:\n",
    "        data[field] = data[field].str.lower()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data = lowercase(sub_train_data)\n",
    "train_data = lowercase(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data, fields=all_text_fields):\n",
    "    def remove(sentence):\n",
    "        if sentence is None:\n",
    "            return None\n",
    "        \n",
    "        if not isinstance(sentence, str):\n",
    "            if math.isnan(sentence):\n",
    "                return None\n",
    "            \n",
    "            print('{} type is {}'.format(sentence, type(sentence)))\n",
    "            return sentence\n",
    "            \n",
    "        tokenizer = RegexpTokenizer(r'\\w+')        \n",
    "        tokenizer = tokenizer.tokenize(sentence)\n",
    "        return ' '.join(tokenizer)\n",
    "    \n",
    "    for field in fields:\n",
    "        data[field] = data[field].apply(remove)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data, fields=all_text_fields): \n",
    "    def remove(sentence):\n",
    "        if sentence is None:\n",
    "            return None\n",
    "        \n",
    "        if not isinstance(sentence, str):\n",
    "            if math.isnan(sentence):\n",
    "                return None\n",
    "            \n",
    "            print('{} type is {}'.format(sentence, type(sentence)))\n",
    "            return sentence\n",
    "    \n",
    "        filtered_words = [w for w in word_tokenize(sentence) \n",
    "                          if not w in stopwords.words('english')]\n",
    "        return ' '.join(filtered_words)\n",
    "    \n",
    "    for field in fields:\n",
    "        data[field] = data[field].apply(remove)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_data = remove_punctuation(sub_train_data)\n",
    "#train_data = remove_punctuation(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_data = remove_stopwords(sub_train_data)\n",
    "#train_data = remove_stopwords(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviation_dict = {\n",
    "    'vs' : 'victoria secret',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_brand_name_list(data):\n",
    "    orig = data['brand_name']\n",
    "    orig = orig[orig.notna()]\n",
    "    # remove duplicated\n",
    "    orig = set(orig)\n",
    "    # remove space in word\n",
    "    orig = [w.replace(' ', '') for w in orig]\n",
    "    return orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_brand_list = build_brand_name_list(sub_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 943 known brand names\n"
     ]
    }
   ],
   "source": [
    "print('there are {} known brand names'.format(len(known_brand_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brand_name_list', 'wb') as f:\n",
    "    pickle.dump(known_brand_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*name* usually contains *brand_name* information. It is able to use *name* to predict missing *brand_name*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_in_list(sent, items=known_brand_list):\n",
    "    candidate = []\n",
    "    for item in items:\n",
    "        match, _ = contains(sent, item)\n",
    "        if match:\n",
    "            candidate.append(item)\n",
    "    else:\n",
    "        return candidate\n",
    "\n",
    "def contains(sent, key_words):\n",
    "    sent = sent.split(' ')\n",
    "    key_words = key_words.split(' ')\n",
    "\n",
    "    match_points = [sent.index(w) for w in key_words if w in sent]\n",
    "\n",
    "    if len(match_points) == 0:\n",
    "        return False, []\n",
    "\n",
    "    matched_index = []\n",
    "    for match_point in match_points:\n",
    "        for i in range(len(key_words)):\n",
    "            if match_point + i >= len(sent)\\\n",
    "                or not sent[match_point + i] == key_words[i]:\n",
    "                break\n",
    "        else:\n",
    "            matched_index.append(match_point)\n",
    "\n",
    "    return len(matched_index) != 0, matched_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name is: iphone 5c\n",
      "actual brand name is apple\n",
      "predict brand name is []\n"
     ]
    }
   ],
   "source": [
    "s = sub_train_data.sample()\n",
    "name = s['name'].to_string(index=False)\n",
    "print('name is: ' + name)\n",
    "print('actual brand name is ' + s['brand_name'].to_string(index=False))\n",
    "print('predict brand name is ' + str(match_in_list(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to fix the missing problem first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6327 items missing item_condition_id\n",
      "there are 58 items missing item_condition_id in sub_train_data\n"
     ]
    }
   ],
   "source": [
    "print(\"there are \" + str(pd.isna(train_data['category_name']).sum())\n",
    "      + \" items missing item_condition_id\")\n",
    "print(\"there are \" + str(pd.isna(sub_train_data['category_name']).sum())\n",
    "      + \" items missing item_condition_id in sub_train_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116650</th>\n",
       "      <td>boys size 8 reg</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>gap</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>boys size 8 regular gap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148297</th>\n",
       "      <td>lacoste 6</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>lacoste</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>says 6 adult size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541465</th>\n",
       "      <td>henna kit</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>never used gift style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236657</th>\n",
       "      <td>rock revival jeans</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>rock revival</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>size 30 waist 30 inseam great pain jeans rips ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489216</th>\n",
       "      <td>coach sandals size 9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>coach</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>description yet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name item_condition_id category_name    brand_name  \\\n",
       "116650        boys size 8 reg                 3          None           gap   \n",
       "1148297             lacoste 6                 3          None       lacoste   \n",
       "541465              henna kit                 1          None          None   \n",
       "236657     rock revival jeans                 3          None  rock revival   \n",
       "489216   coach sandals size 9                 1          None         coach   \n",
       "\n",
       "         price shipping                                   item_description  \n",
       "116650    10.0        0                            boys size 8 regular gap  \n",
       "1148297    7.0        0                                  says 6 adult size  \n",
       "541465     9.0        0                              never used gift style  \n",
       "236657    56.0        0  size 30 waist 30 inseam great pain jeans rips ...  \n",
       "489216    26.0        0                                    description yet  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_data[pd.isna(sub_train_data['category_name'])].sample(n=5, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 687 unique category_names\n"
     ]
    }
   ],
   "source": [
    "print(\"there are {} unique category_names\".format(len(pd.unique(sub_train_data['category_name']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are too much categories and seems tough to use a simple classify algorithm to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_c1 = pd.unique(sub_train_data['c1'])\n",
    "print(\"there are {} unique c1 name: {}\".format(len(unique_c1), unique_c1))\n",
    "\n",
    "print()\n",
    "unique_c2_c1 = {c1_name: pd.unique(sub_train_data[sub_train_data['c1'] == c1_name]['c2'])\n",
    "             for c1_name in unique_c1}\n",
    "for c1_name, c2_names in unique_c2_c1.items():\n",
    "    pprint.pprint(\"there are {} unique c2 name under c1 {}: {}\".format(\n",
    "        len(c2_names), c1_name, c2_names))\n",
    "unique_c2 = pd.unique(sub_train_data['c2'])\n",
    "print(\"there are {} unique c2 name\".format(len(unique_c2)))\n",
    "print()\n",
    "\n",
    "unique_c3_c2 = {c2_name: pd.unique(sub_train_data[sub_train_data['c2'] == c2_name]['c3'])\n",
    "         for c2_name in unique_c2}\n",
    "for c2_name, c3_names in unique_c3_c2.items():\n",
    "    pprint.pprint(\"there are {} unique c3 name under c2 {}: {}\".format(\n",
    "        len(c3_names), c2_name, c3_names))\n",
    "unique_c3 = pd.unique(sub_train_data['c3'])\n",
    "print(\"there are {} unique c3 name\".format(len(unique_c3)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 687 *category_name* is a lot of categories and hard to handle by a classify algorithm, tend to classify to *c1* first, there are only 11 of them. Then classify to *c2* in each *c1*, Then to *c3* in each *c2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_data[sub_train_data['c1'].isna()].sample(n=5, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(sub_train_data['name'])\n",
    "target = list(sub_train_data['c1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of *price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several products which prices are 0. Not sure it is kind of missing data, or they are their real prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data[sub_train_data['price'] == 0].sample(n=3, random_state=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since price zero products include \"cell phone\", \"shoes\", clothes\" and so on, tend to believe they are missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_missing_price(data):\n",
    "    return data[data['price'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data = drop_missing_price(sub_train_data)\n",
    "train_data = drop_missing_price(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "sns.distplot(sub_train_data['price'], ax=ax1)\n",
    "sns.boxplot(x=sub_train_data['price'], ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A long tail distribution shape. Use log to normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_price(data):\n",
    "    data['price'] = np.log(data['price'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data= log_price(sub_train_data)\n",
    "train_data = log_price(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "sns.distplot(sub_train_data['price'], ax=ax1)\n",
    "sns.boxplot(x=sub_train_data['price'], ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of merchandises prices are greater than 5.0 and seems like a lot outliers. But it is not right to put every goods together, like to use paper prices as a standard to mersure necklace prices. It might be a better idea to detect outliers of the price with some kind of category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.5)\n",
    "fig = plt.figure(figsize=(40,24))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "sns.boxplot(x=\"item_condition_id\", y='price', data=sub_train_data, ax=ax1)\n",
    "sns.boxplot(x=\"shipping\", y='price', data=sub_train_data, ax=ax2)\n",
    "\n",
    "plt.show()\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it turns out that,\n",
    "- a product with higher item_condition_id value, the averge price is lower than a product with lower item_condition_id value. So value 5 of item_condition_id means the worse, value 1 means the best\n",
    "- shipping products average prices are higher than non-shipping products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *category_name* -- c1/c2/c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.5)\n",
    "plt.figure(figsize=(24,8))\n",
    "fig = sns.boxplot(x=\"c1\", y='price', data=sub_train_data.dropna())\n",
    "fig.set_xticklabels(sub_train_data['c1'].unique(), rotation=30)\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highest prices of *men* stuff and *electronics* are greater than 1.75 and both lowest are less than 0.25, especially *men* stuff lowest price are almost 0.5, while most categories lowest prices are lower than 0.25 and close to 0.125. prices of *sports & outdoors* are in a small range of (0.75, 1.25]. *women* stuff prices are concentrate in the range of (1.0, 1.6]. *beauty* stuff prices are concentrate in the range of (1.0, 1.25). other categories prices distribute in whole range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=3)\n",
    "fig = plt.figure(figsize=(24,64))\n",
    "sns.stripplot(x=\"price\", y='c2', hue='c1', data=sub_train_data, size=8)\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2.5)\n",
    "fig = plt.figure(figsize=(32,64))\n",
    "\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax3 = fig.add_subplot(313)\n",
    "\n",
    "ax1.set_xticklabels(sub_train_data['c1'].unique(), rotation=30)\n",
    "sns.stripplot(x=\"c1\", y='price', data=sub_train_data, ax=ax1)\n",
    "\n",
    "ax2.set_xticklabels(sub_train_data['c2'].unique())\n",
    "sns.stripplot(x='price', y='c2', data=sub_train_data, ax=ax2)\n",
    "\n",
    "ax3.set_xticklabels(sub_train_data['c3'].unique())\n",
    "sns.stripplot(x='price', y='c3', data=sub_train_data, ax=ax3)\n",
    "\n",
    "plt.show()\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"there are \" + str(pd.isna(train_data['name']).sum())\n",
    "      + \" items missing in name\")\n",
    "print(\"there are \" + str(pd.isna(train_data['category_name']).sum())\n",
    "      + \" items missing in category_name\")\n",
    "print(\"there are \" + str(pd.isna(train_data['brand_name']).sum())\n",
    "      + \" items missing in brand_name\")\n",
    "print(\"there are \" + str(pd.isna(train_data['item_description']).sum())\n",
    "      + \" items missing in item_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_train_data[pd.isna(sub_train_data['category_name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
